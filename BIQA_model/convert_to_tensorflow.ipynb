{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "        transforms.CenterCrop((384, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inceptionresnetv2 import inceptionresnetv2\n",
    "class model_qa(nn.Module):\n",
    "    def __init__(self,num_classes,**kwargs):\n",
    "        super(model_qa,self).__init__()\n",
    "        base_model = inceptionresnetv2(num_classes=1000, pretrained='imagenet')\n",
    "        self.base= nn.Sequential(*list(base_model.children())[:-1])\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(1536, 2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(256),         \n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.base(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_qa(\n",
       "  (base): Sequential(\n",
       "    (0): BasicConv2d(\n",
       "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): BasicConv2d(\n",
       "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): BasicConv2d(\n",
       "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): BasicConv2d(\n",
       "      (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): BasicConv2d(\n",
       "      (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Mixed_5b(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch3): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (4): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (6): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (7): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (8): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (9): Block35(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (branch2): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(128, 320, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (9): Mixed_6a(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(320, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (4): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (6): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (7): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (8): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (9): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (10): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (11): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (12): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (13): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (14): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (15): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (16): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (17): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (18): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (19): Block17(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(1088, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(128, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "            (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(384, 1088, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (11): Mixed_7a(\n",
       "      (branch0): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 288, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch2): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(1088, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(256, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(288, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (branch3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (12): Sequential(\n",
       "      (0): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (2): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (3): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (4): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (5): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (6): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (7): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (8): Block8(\n",
       "        (branch0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (branch1): Sequential(\n",
       "          (0): BasicConv2d(\n",
       "            (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (1): BasicConv2d(\n",
       "            (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "            (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "          (2): BasicConv2d(\n",
       "            (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU()\n",
       "          )\n",
       "        )\n",
       "        (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (13): Block8(\n",
       "      (branch0): BasicConv2d(\n",
       "        (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (branch1): Sequential(\n",
       "        (0): BasicConv2d(\n",
       "          (conv): Conv2d(2080, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (1): BasicConv2d(\n",
       "          (conv): Conv2d(192, 224, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "          (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (2): BasicConv2d(\n",
       "          (conv): Conv2d(224, 256, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (conv2d): Conv2d(448, 2080, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (14): BasicConv2d(\n",
       "      (conv): Conv2d(2080, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(1536, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (15): AvgPool2d(kernel_size=8, stride=8, padding=0)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=2048, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.25, inplace=False)\n",
       "    (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.25, inplace=False)\n",
       "    (8): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Dropout(p=0.5, inplace=False)\n",
       "    (12): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Please follow the instructions in the GitHub page to download the pre-trained model:\n",
    "https://github.com/multimediaeval/2020-Pixel-Privacy-Task\n",
    "'''\n",
    "\n",
    "KonCept512 = model_qa(num_classes=1) \n",
    "KonCept512.load_state_dict(torch.load('./KonCept512.pth'))\n",
    "KonCept512.eval().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BIQA score of image `../pp2020_dev/11396447303.jpg` is 67.12537384033203\n",
      "The BIQA score of image `../pp2020_dev/107505789.jpg` is 57.88755798339844\n",
      "The BIQA score of image `../pp2020_dev/10692667386.jpg` is 65.55703735351562\n"
     ]
    }
   ],
   "source": [
    "img_paths = ['../pp2020_dev/11396447303.jpg', '../pp2020_dev/107505789.jpg', '../pp2020_dev/10692667386.jpg']\n",
    "imgs = [data_transforms(Image.open(img_path).convert('RGB')) for img_path in img_paths]\n",
    "score = KonCept512(torch.stack(imgs).to(device)).detach().cpu().numpy().squeeze()\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    print('The BIQA score of image `{}` is {}'.format(img_path, score[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to TF via ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input_image : Float(1:589824, 3:196608, 384:512, 512:1, requires_grad=0, device=cuda:0),\n",
      "      %base.8.0.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.0.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.1.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.1.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.2.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.2.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.3.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.3.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.4.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.4.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.5.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.5.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.6.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.6.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.7.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.7.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.8.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.8.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.9.conv2d.weight : Float(320:128, 128:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.8.9.conv2d.bias : Float(320:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.0.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.0.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.1.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.1.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.2.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.2.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.3.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.3.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.4.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.4.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.5.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.5.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.6.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.6.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.7.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.7.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.8.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.8.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.9.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.9.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.10.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.10.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.11.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.11.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.12.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.12.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.13.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.13.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.14.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.14.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.15.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.15.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.16.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.16.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.17.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.17.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.18.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.18.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.19.conv2d.weight : Float(1088:384, 384:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.10.19.conv2d.bias : Float(1088:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.0.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.0.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.1.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.1.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.2.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.2.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.3.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.3.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.4.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.4.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.5.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.5.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.6.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.6.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.7.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.7.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.8.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.12.8.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %base.13.conv2d.weight : Float(2080:448, 448:1, 1:1, 1:1, requires_grad=1, device=cuda:0),\n",
      "      %base.13.conv2d.bias : Float(2080:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.0.weight : Float(2048:1536, 1536:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.0.bias : Float(2048:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.2.weight : Float(2048:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.2.bias : Float(2048:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.2.running_mean : Float(2048:1, requires_grad=0, device=cuda:0),\n",
      "      %fc.2.running_var : Float(2048:1, requires_grad=0, device=cuda:0),\n",
      "      %fc.4.weight : Float(1024:2048, 2048:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.4.bias : Float(1024:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.6.weight : Float(1024:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.6.bias : Float(1024:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.6.running_mean : Float(1024:1, requires_grad=0, device=cuda:0),\n",
      "      %fc.6.running_var : Float(1024:1, requires_grad=0, device=cuda:0),\n",
      "      %fc.8.weight : Float(256:1024, 1024:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.8.bias : Float(256:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.10.weight : Float(256:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.10.bias : Float(256:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.10.running_mean : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %fc.10.running_var : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %fc.12.weight : Float(1:256, 256:1, requires_grad=1, device=cuda:0),\n",
      "      %fc.12.bias : Float(1:1, requires_grad=1, device=cuda:0),\n",
      "      %2207 : Float(32:27, 3:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2208 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2210 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2211 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2213 : Float(64:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2214 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2216 : Float(80:64, 64:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2217 : Float(80:1, requires_grad=0, device=cuda:0),\n",
      "      %2219 : Float(192:720, 80:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2220 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2222 : Float(96:192, 192:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2223 : Float(96:1, requires_grad=0, device=cuda:0),\n",
      "      %2225 : Float(48:192, 192:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2226 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2228 : Float(64:1200, 48:25, 5:5, 5:1, requires_grad=0, device=cuda:0),\n",
      "      %2229 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2231 : Float(64:192, 192:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2232 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2234 : Float(96:576, 64:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2235 : Float(96:1, requires_grad=0, device=cuda:0),\n",
      "      %2237 : Float(96:864, 96:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2238 : Float(96:1, requires_grad=0, device=cuda:0),\n",
      "      %2240 : Float(64:192, 192:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2241 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2243 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2244 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2246 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2247 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2249 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2250 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2252 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2253 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2255 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2256 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2258 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2259 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2261 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2262 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2264 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2265 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2267 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2268 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2270 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2271 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2273 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2274 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2276 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2277 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2279 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2280 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2282 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2283 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2285 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2286 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2288 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2289 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2291 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2292 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2294 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2295 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2297 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2298 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2300 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2301 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2303 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2304 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2306 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2307 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2309 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2310 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2312 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2313 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2315 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2316 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2318 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2319 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2321 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2322 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2324 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2325 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2327 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2328 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2330 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2331 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2333 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2334 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2336 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2337 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2339 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2340 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2342 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2343 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2345 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2346 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2348 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2349 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2351 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2352 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2354 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2355 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2357 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2358 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2360 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2361 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2363 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2364 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2366 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2367 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2369 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2370 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2372 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2373 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2375 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2376 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2378 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2379 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2381 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2382 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2384 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2385 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2387 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2388 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2390 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2391 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2393 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2394 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2396 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2397 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2399 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2400 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2402 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2403 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2405 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2406 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2408 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2409 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2411 : Float(32:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2412 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2414 : Float(32:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2415 : Float(32:1, requires_grad=0, device=cuda:0),\n",
      "      %2417 : Float(48:288, 32:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2418 : Float(48:1, requires_grad=0, device=cuda:0),\n",
      "      %2420 : Float(64:432, 48:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2421 : Float(64:1, requires_grad=0, device=cuda:0),\n",
      "      %2423 : Float(384:2880, 320:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2424 : Float(384:1, requires_grad=0, device=cuda:0),\n",
      "      %2426 : Float(256:320, 320:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2427 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2429 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2430 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2432 : Float(384:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2433 : Float(384:1, requires_grad=0, device=cuda:0),\n",
      "      %2435 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2436 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2438 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2439 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2441 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2442 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2444 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2445 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2447 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2448 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2450 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2451 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2453 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2454 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2456 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2457 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2459 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2460 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2462 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2463 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2465 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2466 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2468 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2469 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2471 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2472 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2474 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2475 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2477 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2478 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2480 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2481 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2483 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2484 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2486 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2487 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2489 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2490 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2492 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2493 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2495 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2496 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2498 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2499 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2501 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2502 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2504 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2505 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2507 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2508 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2510 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2511 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2513 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2514 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2516 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2517 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2519 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2520 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2522 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2523 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2525 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2526 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2528 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2529 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2531 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2532 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2534 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2535 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2537 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2538 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2540 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2541 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2543 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2544 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2546 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2547 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2549 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2550 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2552 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2553 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2555 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2556 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2558 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2559 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2561 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2562 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2564 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2565 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2567 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2568 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2570 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2571 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2573 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2574 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2576 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2577 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2579 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2580 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2582 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2583 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2585 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2586 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2588 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2589 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2591 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2592 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2594 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2595 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2597 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2598 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2600 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2601 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2603 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2604 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2606 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2607 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2609 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2610 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2612 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2613 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2615 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2616 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2618 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2619 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2621 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2622 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2624 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2625 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2627 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2628 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2630 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2631 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2633 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2634 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2636 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2637 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2639 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2640 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2642 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2643 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2645 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2646 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2648 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2649 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2651 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2652 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2654 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2655 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2657 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2658 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2660 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2661 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2663 : Float(192:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2664 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2666 : Float(128:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2667 : Float(128:1, requires_grad=0, device=cuda:0),\n",
      "      %2669 : Float(160:896, 128:7, 1:7, 7:1, requires_grad=0, device=cuda:0),\n",
      "      %2670 : Float(160:1, requires_grad=0, device=cuda:0),\n",
      "      %2672 : Float(192:1120, 160:7, 7:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2673 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2675 : Float(256:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2676 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2678 : Float(384:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2679 : Float(384:1, requires_grad=0, device=cuda:0),\n",
      "      %2681 : Float(256:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2682 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2684 : Float(288:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2685 : Float(288:1, requires_grad=0, device=cuda:0),\n",
      "      %2687 : Float(256:1088, 1088:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2688 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2690 : Float(288:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2691 : Float(288:1, requires_grad=0, device=cuda:0),\n",
      "      %2693 : Float(320:2592, 288:9, 3:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2694 : Float(320:1, requires_grad=0, device=cuda:0),\n",
      "      %2696 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2697 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2699 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2700 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2702 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2703 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2705 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2706 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2708 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2709 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2711 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2712 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2714 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2715 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2717 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2718 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2720 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2721 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2723 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2724 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2726 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2727 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2729 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2730 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2732 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2733 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2735 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2736 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2738 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2739 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2741 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2742 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2744 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2745 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2747 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2748 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2750 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2751 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2753 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2754 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2756 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2757 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2759 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2760 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2762 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2763 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2765 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2766 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2768 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2769 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2771 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2772 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2774 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2775 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2777 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2778 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2780 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2781 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2783 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2784 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2786 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2787 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2789 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2790 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2792 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2793 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2795 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2796 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2798 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2799 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2801 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2802 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2804 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2805 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2807 : Float(192:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2808 : Float(192:1, requires_grad=0, device=cuda:0),\n",
      "      %2810 : Float(224:576, 192:3, 1:3, 3:1, requires_grad=0, device=cuda:0),\n",
      "      %2811 : Float(224:1, requires_grad=0, device=cuda:0),\n",
      "      %2813 : Float(256:672, 224:3, 3:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2814 : Float(256:1, requires_grad=0, device=cuda:0),\n",
      "      %2816 : Float(1536:2080, 2080:1, 1:1, 1:1, requires_grad=0, device=cuda:0),\n",
      "      %2817 : Float(1536:1, requires_grad=0, device=cuda:0),\n",
      "      %2818 : Long(1:1, requires_grad=0, device=cpu)):\n",
      "  %2206 : Float(1:1558560, 32:48705, 191:255, 255:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%input_image, %2207, %2208)\n",
      "  %1330 : Float(1:1558560, 32:48705, 191:255, 255:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2206) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2209 : Float(1:1530144, 32:47817, 189:253, 253:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%1330, %2210, %2211)\n",
      "  %1333 : Float(1:1530144, 32:47817, 189:253, 253:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2209) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2212 : Float(1:3060288, 64:47817, 189:253, 253:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1333, %2213, %2214)\n",
      "  %1336 : Float(1:3060288, 64:47817, 189:253, 253:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2212) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1337 : Float(1:758016, 64:11844, 94:126, 126:1, requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1336) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:585:0\n",
      "  %2215 : Float(1:947520, 80:11844, 94:126, 126:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1337, %2216, %2217)\n",
      "  %1340 : Float(1:947520, 80:11844, 94:126, 126:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2215) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2218 : Float(1:2190336, 192:11408, 92:124, 124:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[1, 1]](%1340, %2219, %2220)\n",
      "  %1343 : Float(1:2190336, 192:11408, 92:124, 124:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2218) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1344 : Float(1:527040, 192:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1343) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:585:0\n",
      "  %2221 : Float(1:263520, 96:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1344, %2222, %2223)\n",
      "  %1347 : Float(1:263520, 96:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2221) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2224 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1344, %2225, %2226)\n",
      "  %1350 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2224) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2227 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[5, 5], pads=[2, 2, 2, 2], strides=[1, 1]](%1350, %2228, %2229)\n",
      "  %1353 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2227) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2230 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1344, %2231, %2232)\n",
      "  %1356 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2230) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2233 : Float(1:263520, 96:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1356, %2234, %2235)\n",
      "  %1359 : Float(1:263520, 96:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2233) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2236 : Float(1:263520, 96:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1359, %2237, %2238)\n",
      "  %1362 : Float(1:263520, 96:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2236) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1363 : Float(1:527040, 192:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::AveragePool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1344) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/pooling.py:594:0\n",
      "  %2239 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1363, %2240, %2241)\n",
      "  %1366 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2239) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1367 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1347, %1353, %1362, %1366) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:82:0\n",
      "  %2242 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1367, %2243, %2244)\n",
      "  %1370 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2242) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2245 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1367, %2246, %2247)\n",
      "  %1373 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2245) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2248 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1373, %2249, %2250)\n",
      "  %1376 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2248) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2251 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1367, %2252, %2253)\n",
      "  %1379 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2251) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2254 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1379, %2255, %2256)\n",
      "  %1382 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2254) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2257 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1382, %2258, %2259)\n",
      "  %1385 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2257) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1386 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1370, %1376, %1385) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1387 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1386, %base.8.0.conv2d.weight, %base.8.0.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1388 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1389 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1387, %1388)\n",
      "  %1390 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1389, %1367) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1391 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1390) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2260 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1391, %2261, %2262)\n",
      "  %1394 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2260) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2263 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1391, %2264, %2265)\n",
      "  %1397 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2263) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2266 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1397, %2267, %2268)\n",
      "  %1400 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2266) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2269 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1391, %2270, %2271)\n",
      "  %1403 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2269) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2272 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1403, %2273, %2274)\n",
      "  %1406 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2272) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2275 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1406, %2276, %2277)\n",
      "  %1409 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2275) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1410 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1394, %1400, %1409) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1411 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1410, %base.8.1.conv2d.weight, %base.8.1.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1412 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1413 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1411, %1412)\n",
      "  %1414 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1413, %1391) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1415 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1414) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2278 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1415, %2279, %2280)\n",
      "  %1418 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2278) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2281 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1415, %2282, %2283)\n",
      "  %1421 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2281) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2284 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1421, %2285, %2286)\n",
      "  %1424 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2284) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2287 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1415, %2288, %2289)\n",
      "  %1427 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2287) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2290 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1427, %2291, %2292)\n",
      "  %1430 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2290) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2293 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1430, %2294, %2295)\n",
      "  %1433 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2293) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1434 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1418, %1424, %1433) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1435 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1434, %base.8.2.conv2d.weight, %base.8.2.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1436 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1437 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1435, %1436)\n",
      "  %1438 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1437, %1415) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1439 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1438) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2296 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1439, %2297, %2298)\n",
      "  %1442 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2296) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2299 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1439, %2300, %2301)\n",
      "  %1445 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2299) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2302 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1445, %2303, %2304)\n",
      "  %1448 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2302) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2305 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1439, %2306, %2307)\n",
      "  %1451 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2305) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2308 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1451, %2309, %2310)\n",
      "  %1454 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2308) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2311 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1454, %2312, %2313)\n",
      "  %1457 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2311) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1458 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1442, %1448, %1457) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1459 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1458, %base.8.3.conv2d.weight, %base.8.3.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1460 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1461 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1459, %1460)\n",
      "  %1462 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1461, %1439) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1463 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1462) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2314 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1463, %2315, %2316)\n",
      "  %1466 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2314) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2317 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1463, %2318, %2319)\n",
      "  %1469 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2317) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2320 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1469, %2321, %2322)\n",
      "  %1472 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2320) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2323 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1463, %2324, %2325)\n",
      "  %1475 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2323) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2326 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1475, %2327, %2328)\n",
      "  %1478 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2326) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2329 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1478, %2330, %2331)\n",
      "  %1481 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2329) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1482 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1466, %1472, %1481) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1483 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1482, %base.8.4.conv2d.weight, %base.8.4.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1484 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1485 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1483, %1484)\n",
      "  %1486 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1485, %1463) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1487 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1486) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2332 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1487, %2333, %2334)\n",
      "  %1490 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2332) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2335 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1487, %2336, %2337)\n",
      "  %1493 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2335) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2338 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1493, %2339, %2340)\n",
      "  %1496 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2338) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2341 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1487, %2342, %2343)\n",
      "  %1499 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2341) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2344 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1499, %2345, %2346)\n",
      "  %1502 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2344) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2347 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1502, %2348, %2349)\n",
      "  %1505 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2347) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1506 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1490, %1496, %1505) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1507 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1506, %base.8.5.conv2d.weight, %base.8.5.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1508 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1509 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1507, %1508)\n",
      "  %1510 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1509, %1487) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1511 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1510) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2350 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1511, %2351, %2352)\n",
      "  %1514 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2350) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2353 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1511, %2354, %2355)\n",
      "  %1517 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2353) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2356 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1517, %2357, %2358)\n",
      "  %1520 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2356) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2359 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1511, %2360, %2361)\n",
      "  %1523 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2359) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2362 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1523, %2363, %2364)\n",
      "  %1526 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2362) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2365 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1526, %2366, %2367)\n",
      "  %1529 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2365) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1530 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1514, %1520, %1529) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1531 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1530, %base.8.6.conv2d.weight, %base.8.6.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1532 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1533 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1531, %1532)\n",
      "  %1534 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1533, %1511) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1535 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1534) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2368 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1535, %2369, %2370)\n",
      "  %1538 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2368) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2371 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1535, %2372, %2373)\n",
      "  %1541 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2371) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2374 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1541, %2375, %2376)\n",
      "  %1544 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2374) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2377 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1535, %2378, %2379)\n",
      "  %1547 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2377) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2380 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1547, %2381, %2382)\n",
      "  %1550 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2380) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2383 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1550, %2384, %2385)\n",
      "  %1553 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2383) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1554 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1538, %1544, %1553) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1555 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1554, %base.8.7.conv2d.weight, %base.8.7.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1556 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1557 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1555, %1556)\n",
      "  %1558 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1557, %1535) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1559 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1558) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2386 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1559, %2387, %2388)\n",
      "  %1562 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2386) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2389 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1559, %2390, %2391)\n",
      "  %1565 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2389) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2392 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1565, %2393, %2394)\n",
      "  %1568 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2392) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2395 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1559, %2396, %2397)\n",
      "  %1571 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2395) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2398 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1571, %2399, %2400)\n",
      "  %1574 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2398) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2401 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1574, %2402, %2403)\n",
      "  %1577 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2401) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1578 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1562, %1568, %1577) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1579 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1578, %base.8.8.conv2d.weight, %base.8.8.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1580 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1581 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1579, %1580)\n",
      "  %1582 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1581, %1559) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1583 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1582) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2404 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1583, %2405, %2406)\n",
      "  %1586 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2404) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2407 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1583, %2408, %2409)\n",
      "  %1589 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2407) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2410 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1589, %2411, %2412)\n",
      "  %1592 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2410) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2413 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1583, %2414, %2415)\n",
      "  %1595 : Float(1:87840, 32:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2413) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2416 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1595, %2417, %2418)\n",
      "  %1598 : Float(1:131760, 48:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2416) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2419 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1598, %2420, %2421)\n",
      "  %1601 : Float(1:175680, 64:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2419) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1602 : Float(1:351360, 128:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1586, %1592, %1601) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:113:0\n",
      "  %1603 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1602, %base.8.9.conv2d.weight, %base.8.9.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1604 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.17}]()\n",
      "  %1605 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1603, %1604)\n",
      "  %1606 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Add(%1605, %1583) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:115:0\n",
      "  %1607 : Float(1:878400, 320:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1606) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2422 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1607, %2423, %2424)\n",
      "  %1610 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2422) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2425 : Float(1:702720, 256:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1607, %2426, %2427)\n",
      "  %1613 : Float(1:702720, 256:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2425) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2428 : Float(1:702720, 256:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1613, %2429, %2430)\n",
      "  %1616 : Float(1:702720, 256:2745, 45:61, 61:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2428) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2431 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1616, %2432, %2433)\n",
      "  %1619 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2431) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1620 : Float(1:211200, 320:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1607) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:585:0\n",
      "  %1621 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1610, %1619, %1620) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:139:0\n",
      "  %2434 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1621, %2435, %2436)\n",
      "  %1624 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2434) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2437 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1621, %2438, %2439)\n",
      "  %1627 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2437) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2440 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1627, %2441, %2442)\n",
      "  %1630 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2440) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2443 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1630, %2444, %2445)\n",
      "  %1633 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2443) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1634 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1624, %1633) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1635 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1634, %base.10.0.conv2d.weight, %base.10.0.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1636 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1637 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1635, %1636)\n",
      "  %1638 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1637, %1621) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1639 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1638) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2446 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1639, %2447, %2448)\n",
      "  %1642 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2446) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2449 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1639, %2450, %2451)\n",
      "  %1645 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2449) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2452 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1645, %2453, %2454)\n",
      "  %1648 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2452) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2455 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1648, %2456, %2457)\n",
      "  %1651 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2455) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1652 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1642, %1651) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1653 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1652, %base.10.1.conv2d.weight, %base.10.1.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1654 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1655 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1653, %1654)\n",
      "  %1656 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1655, %1639) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1657 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1656) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2458 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1657, %2459, %2460)\n",
      "  %1660 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2458) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2461 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1657, %2462, %2463)\n",
      "  %1663 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2461) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2464 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1663, %2465, %2466)\n",
      "  %1666 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2464) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2467 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1666, %2468, %2469)\n",
      "  %1669 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2467) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1670 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1660, %1669) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1671 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1670, %base.10.2.conv2d.weight, %base.10.2.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1672 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1673 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1671, %1672)\n",
      "  %1674 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1673, %1657) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1675 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1674) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2470 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1675, %2471, %2472)\n",
      "  %1678 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2470) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2473 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1675, %2474, %2475)\n",
      "  %1681 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2473) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2476 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1681, %2477, %2478)\n",
      "  %1684 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2476) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2479 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1684, %2480, %2481)\n",
      "  %1687 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2479) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1688 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1678, %1687) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1689 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1688, %base.10.3.conv2d.weight, %base.10.3.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1690 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1691 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1689, %1690)\n",
      "  %1692 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1691, %1675) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1693 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1692) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2482 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1693, %2483, %2484)\n",
      "  %1696 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2482) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2485 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1693, %2486, %2487)\n",
      "  %1699 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2485) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2488 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1699, %2489, %2490)\n",
      "  %1702 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2488) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2491 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1702, %2492, %2493)\n",
      "  %1705 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2491) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1706 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1696, %1705) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1707 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1706, %base.10.4.conv2d.weight, %base.10.4.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1708 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1709 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1707, %1708)\n",
      "  %1710 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1709, %1693) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1711 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1710) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2494 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1711, %2495, %2496)\n",
      "  %1714 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2494) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2497 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1711, %2498, %2499)\n",
      "  %1717 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2497) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2500 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1717, %2501, %2502)\n",
      "  %1720 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2500) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2503 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1720, %2504, %2505)\n",
      "  %1723 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2503) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1724 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1714, %1723) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1725 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1724, %base.10.5.conv2d.weight, %base.10.5.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1726 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1727 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1725, %1726)\n",
      "  %1728 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1727, %1711) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1729 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1728) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2506 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1729, %2507, %2508)\n",
      "  %1732 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2506) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2509 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1729, %2510, %2511)\n",
      "  %1735 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2509) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2512 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1735, %2513, %2514)\n",
      "  %1738 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2512) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2515 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1738, %2516, %2517)\n",
      "  %1741 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2515) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1742 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1732, %1741) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1743 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1742, %base.10.6.conv2d.weight, %base.10.6.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1744 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1745 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1743, %1744)\n",
      "  %1746 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1745, %1729) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1747 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1746) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2518 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1747, %2519, %2520)\n",
      "  %1750 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2518) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2521 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1747, %2522, %2523)\n",
      "  %1753 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2521) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2524 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1753, %2525, %2526)\n",
      "  %1756 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2524) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2527 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1756, %2528, %2529)\n",
      "  %1759 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2527) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1760 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1750, %1759) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1761 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1760, %base.10.7.conv2d.weight, %base.10.7.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1762 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1763 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1761, %1762)\n",
      "  %1764 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1763, %1747) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1765 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1764) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2530 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1765, %2531, %2532)\n",
      "  %1768 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2530) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2533 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1765, %2534, %2535)\n",
      "  %1771 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2533) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2536 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1771, %2537, %2538)\n",
      "  %1774 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2536) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2539 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1774, %2540, %2541)\n",
      "  %1777 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2539) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1778 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1768, %1777) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1779 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1778, %base.10.8.conv2d.weight, %base.10.8.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1780 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1781 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1779, %1780)\n",
      "  %1782 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1781, %1765) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1783 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1782) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2542 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1783, %2543, %2544)\n",
      "  %1786 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2542) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2545 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1783, %2546, %2547)\n",
      "  %1789 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2545) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2548 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1789, %2549, %2550)\n",
      "  %1792 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2548) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2551 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1792, %2552, %2553)\n",
      "  %1795 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2551) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1796 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1786, %1795) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1797 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1796, %base.10.9.conv2d.weight, %base.10.9.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1798 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1799 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1797, %1798)\n",
      "  %1800 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1799, %1783) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1801 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1800) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2554 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1801, %2555, %2556)\n",
      "  %1804 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2554) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2557 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1801, %2558, %2559)\n",
      "  %1807 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2557) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2560 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1807, %2561, %2562)\n",
      "  %1810 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2560) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2563 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1810, %2564, %2565)\n",
      "  %1813 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2563) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1814 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1804, %1813) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1815 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1814, %base.10.10.conv2d.weight, %base.10.10.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1816 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1817 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1815, %1816)\n",
      "  %1818 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1817, %1801) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1819 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1818) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2566 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1819, %2567, %2568)\n",
      "  %1822 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2566) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2569 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1819, %2570, %2571)\n",
      "  %1825 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2569) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2572 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1825, %2573, %2574)\n",
      "  %1828 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2572) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2575 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1828, %2576, %2577)\n",
      "  %1831 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2575) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1832 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1822, %1831) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1833 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1832, %base.10.11.conv2d.weight, %base.10.11.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1834 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1835 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1833, %1834)\n",
      "  %1836 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1835, %1819) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1837 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1836) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2578 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1837, %2579, %2580)\n",
      "  %1840 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2578) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2581 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1837, %2582, %2583)\n",
      "  %1843 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2581) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2584 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1843, %2585, %2586)\n",
      "  %1846 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2584) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2587 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1846, %2588, %2589)\n",
      "  %1849 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2587) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1850 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1840, %1849) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1851 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1850, %base.10.12.conv2d.weight, %base.10.12.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1852 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1853 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1851, %1852)\n",
      "  %1854 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1853, %1837) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1855 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1854) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2590 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1855, %2591, %2592)\n",
      "  %1858 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2590) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2593 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1855, %2594, %2595)\n",
      "  %1861 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2593) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2596 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1861, %2597, %2598)\n",
      "  %1864 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2596) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2599 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1864, %2600, %2601)\n",
      "  %1867 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2599) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1868 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1858, %1867) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1869 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1868, %base.10.13.conv2d.weight, %base.10.13.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1870 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1871 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1869, %1870)\n",
      "  %1872 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1871, %1855) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1873 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1872) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2602 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1873, %2603, %2604)\n",
      "  %1876 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2602) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2605 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1873, %2606, %2607)\n",
      "  %1879 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2605) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2608 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1879, %2609, %2610)\n",
      "  %1882 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2608) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2611 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1882, %2612, %2613)\n",
      "  %1885 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2611) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1886 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1876, %1885) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1887 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1886, %base.10.14.conv2d.weight, %base.10.14.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1888 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1889 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1887, %1888)\n",
      "  %1890 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1889, %1873) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1891 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1890) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2614 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1891, %2615, %2616)\n",
      "  %1894 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2614) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2617 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1891, %2618, %2619)\n",
      "  %1897 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2617) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2620 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1897, %2621, %2622)\n",
      "  %1900 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2620) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2623 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1900, %2624, %2625)\n",
      "  %1903 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2623) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1904 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1894, %1903) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1905 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1904, %base.10.15.conv2d.weight, %base.10.15.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1906 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1907 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1905, %1906)\n",
      "  %1908 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1907, %1891) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1909 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1908) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2626 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1909, %2627, %2628)\n",
      "  %1912 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2626) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2629 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1909, %2630, %2631)\n",
      "  %1915 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2629) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2632 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1915, %2633, %2634)\n",
      "  %1918 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2632) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2635 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1918, %2636, %2637)\n",
      "  %1921 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2635) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1922 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1912, %1921) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1923 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1922, %base.10.16.conv2d.weight, %base.10.16.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1924 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1925 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1923, %1924)\n",
      "  %1926 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1925, %1909) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1927 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1926) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2638 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1927, %2639, %2640)\n",
      "  %1930 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2638) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2641 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1927, %2642, %2643)\n",
      "  %1933 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2641) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2644 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1933, %2645, %2646)\n",
      "  %1936 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2644) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2647 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1936, %2648, %2649)\n",
      "  %1939 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2647) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1940 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1930, %1939) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1941 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1940, %base.10.17.conv2d.weight, %base.10.17.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1942 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1943 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1941, %1942)\n",
      "  %1944 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1943, %1927) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1945 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1944) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2650 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1945, %2651, %2652)\n",
      "  %1948 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2650) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2653 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1945, %2654, %2655)\n",
      "  %1951 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2653) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2656 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1951, %2657, %2658)\n",
      "  %1954 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2656) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2659 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1954, %2660, %2661)\n",
      "  %1957 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2659) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1958 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1948, %1957) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1959 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1958, %base.10.18.conv2d.weight, %base.10.18.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1960 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1961 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1959, %1960)\n",
      "  %1962 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1961, %1945) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1963 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1962) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2662 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1963, %2663, %2664)\n",
      "  %1966 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2662) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2665 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1963, %2666, %2667)\n",
      "  %1969 : Float(1:84480, 128:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2665) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2668 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 7], pads=[0, 3, 0, 3], strides=[1, 1]](%1969, %2669, %2670)\n",
      "  %1972 : Float(1:105600, 160:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2668) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2671 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 1], pads=[3, 0, 3, 0], strides=[1, 1]](%1972, %2672, %2673)\n",
      "  %1975 : Float(1:126720, 192:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2671) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %1976 : Float(1:253440, 384:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1966, %1975) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:164:0\n",
      "  %1977 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1976, %base.10.19.conv2d.weight, %base.10.19.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %1978 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.1}]()\n",
      "  %1979 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Mul(%1977, %1978)\n",
      "  %1980 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Add(%1979, %1963) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:166:0\n",
      "  %1981 : Float(1:718080, 1088:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%1980) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2674 : Float(1:168960, 256:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1981, %2675, %2676)\n",
      "  %1984 : Float(1:168960, 256:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2674) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2677 : Float(1:53760, 384:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1984, %2678, %2679)\n",
      "  %1987 : Float(1:53760, 384:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2677) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2680 : Float(1:168960, 256:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1981, %2681, %2682)\n",
      "  %1990 : Float(1:168960, 256:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2680) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2683 : Float(1:40320, 288:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1990, %2684, %2685)\n",
      "  %1993 : Float(1:40320, 288:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2683) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2686 : Float(1:168960, 256:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1981, %2687, %2688)\n",
      "  %1996 : Float(1:168960, 256:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2686) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2689 : Float(1:190080, 288:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1996, %2690, %2691)\n",
      "  %1999 : Float(1:190080, 288:660, 22:30, 30:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2689) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2692 : Float(1:44800, 320:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1999, %2693, %2694)\n",
      "  %2002 : Float(1:44800, 320:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2692) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2003 : Float(1:152320, 1088:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%1981) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:585:0\n",
      "  %2004 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%1987, %1993, %2002, %2003) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:199:0\n",
      "  %2695 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2004, %2696, %2697)\n",
      "  %2007 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2695) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2698 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2004, %2699, %2700)\n",
      "  %2010 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2698) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2701 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2010, %2702, %2703)\n",
      "  %2013 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2701) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2704 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2013, %2705, %2706)\n",
      "  %2016 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2704) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2017 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2007, %2016) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2018 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2017, %base.12.0.conv2d.weight, %base.12.0.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2019 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2020 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2018, %2019)\n",
      "  %2021 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2020, %2004) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2022 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2021) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2707 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2022, %2708, %2709)\n",
      "  %2025 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2707) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2710 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2022, %2711, %2712)\n",
      "  %2028 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2710) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2713 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2028, %2714, %2715)\n",
      "  %2031 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2713) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2716 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2031, %2717, %2718)\n",
      "  %2034 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2716) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2035 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2025, %2034) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2036 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2035, %base.12.1.conv2d.weight, %base.12.1.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2037 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2038 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2036, %2037)\n",
      "  %2039 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2038, %2022) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2040 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2039) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2719 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2040, %2720, %2721)\n",
      "  %2043 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2719) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2722 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2040, %2723, %2724)\n",
      "  %2046 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2722) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2725 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2046, %2726, %2727)\n",
      "  %2049 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2725) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2728 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2049, %2729, %2730)\n",
      "  %2052 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2728) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2053 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2043, %2052) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2054 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2053, %base.12.2.conv2d.weight, %base.12.2.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2055 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2056 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2054, %2055)\n",
      "  %2057 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2056, %2040) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2058 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2057) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2731 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2058, %2732, %2733)\n",
      "  %2061 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2731) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2734 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2058, %2735, %2736)\n",
      "  %2064 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2734) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2737 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2064, %2738, %2739)\n",
      "  %2067 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2737) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2740 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2067, %2741, %2742)\n",
      "  %2070 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2740) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2071 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2061, %2070) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2072 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2071, %base.12.3.conv2d.weight, %base.12.3.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2073 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2074 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2072, %2073)\n",
      "  %2075 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2074, %2058) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2076 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2075) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2743 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2076, %2744, %2745)\n",
      "  %2079 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2743) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2746 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2076, %2747, %2748)\n",
      "  %2082 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2746) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2749 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2082, %2750, %2751)\n",
      "  %2085 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2749) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2752 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2085, %2753, %2754)\n",
      "  %2088 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2752) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2089 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2079, %2088) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2090 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2089, %base.12.4.conv2d.weight, %base.12.4.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2091 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2092 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2090, %2091)\n",
      "  %2093 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2092, %2076) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2094 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2093) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2755 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2094, %2756, %2757)\n",
      "  %2097 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2755) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2758 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2094, %2759, %2760)\n",
      "  %2100 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2758) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2761 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2100, %2762, %2763)\n",
      "  %2103 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2761) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2764 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2103, %2765, %2766)\n",
      "  %2106 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2764) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2107 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2097, %2106) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2108 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2107, %base.12.5.conv2d.weight, %base.12.5.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2109 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2110 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2108, %2109)\n",
      "  %2111 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2110, %2094) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2112 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2111) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2767 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2112, %2768, %2769)\n",
      "  %2115 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2767) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2770 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2112, %2771, %2772)\n",
      "  %2118 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2770) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2773 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2118, %2774, %2775)\n",
      "  %2121 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2773) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2776 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2121, %2777, %2778)\n",
      "  %2124 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2776) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2125 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2115, %2124) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2126 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2125, %base.12.6.conv2d.weight, %base.12.6.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2127 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2128 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2126, %2127)\n",
      "  %2129 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2128, %2112) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2130 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2129) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2779 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2130, %2780, %2781)\n",
      "  %2133 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2779) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2782 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2130, %2783, %2784)\n",
      "  %2136 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2782) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2785 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2136, %2786, %2787)\n",
      "  %2139 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2785) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2788 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2139, %2789, %2790)\n",
      "  %2142 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2788) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2143 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2133, %2142) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2144 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2143, %base.12.7.conv2d.weight, %base.12.7.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2145 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2146 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2144, %2145)\n",
      "  %2147 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2146, %2130) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2148 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2147) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2791 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2148, %2792, %2793)\n",
      "  %2151 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2791) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2794 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2148, %2795, %2796)\n",
      "  %2154 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2794) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2797 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2154, %2798, %2799)\n",
      "  %2157 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2797) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2800 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2157, %2801, %2802)\n",
      "  %2160 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2800) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2161 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2151, %2160) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2162 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2161, %base.12.8.conv2d.weight, %base.12.8.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2163 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.2}]()\n",
      "  %2164 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2162, %2163)\n",
      "  %2165 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2164, %2148) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2166 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2165) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2803 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2166, %2804, %2805)\n",
      "  %2169 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2803) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2806 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2166, %2807, %2808)\n",
      "  %2172 : Float(1:26880, 192:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2806) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2809 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 3], pads=[0, 1, 0, 1], strides=[1, 1]](%2172, %2810, %2811)\n",
      "  %2175 : Float(1:31360, 224:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2809) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2812 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 1], pads=[1, 0, 1, 0], strides=[1, 1]](%2175, %2813, %2814)\n",
      "  %2178 : Float(1:35840, 256:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2812) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2179 : Float(1:62720, 448:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Concat[axis=1](%2169, %2178) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:226:0\n",
      "  %2180 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2179, %base.13.conv2d.weight, %base.13.conv2d.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/conv.py:419:0\n",
      "  %2181 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
      "  %2182 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Mul(%2180, %2181)\n",
      "  %2183 : Float(1:291200, 2080:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Add(%2182, %2166) # /home/mathsci/n-cript/2020-Pixel-Privacy-Task-master/BIQA_model/inceptionresnetv2.py:228:0\n",
      "  %2815 : Float(1:215040, 1536:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%2183, %2816, %2817)\n",
      "  %2186 : Float(1:215040, 1536:140, 10:14, 14:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2815) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1136:0\n",
      "  %2187 : Float(1:1536, 1536:1, 1:1, 1:1, requires_grad=1, device=cuda:0) = onnx::AveragePool[kernel_shape=[8, 8], pads=[0, 0, 0, 0], strides=[8, 8]](%2186) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/modules/pooling.py:594:0\n",
      "  %2188 : Tensor = onnx::Shape(%2187)\n",
      "  %2189 : Tensor = onnx::Constant[value={0}]()\n",
      "  %2190 : Long(device=cpu) = onnx::Gather[axis=0](%2188, %2189) # <ipython-input-3-8eb754d50d91>:25:0\n",
      "  %2192 : Tensor = onnx::Unsqueeze[axes=[0]](%2190)\n",
      "  %2194 : Tensor = onnx::Concat[axis=0](%2192, %2818)\n",
      "  %2195 : Float(1:1536, 1536:1, requires_grad=1, device=cuda:0) = onnx::Reshape(%2187, %2194) # <ipython-input-3-8eb754d50d91>:25:0\n",
      "  %2196 : Float(1:2048, 2048:1, requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%2195, %fc.0.weight, %fc.0.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1690:0\n",
      "  %2197 : Float(1:2048, 2048:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2196) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1134:0\n",
      "  %2198 : Float(1:2048, 2048:1, requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%2197, %fc.2.weight, %fc.2.bias, %fc.2.running_mean, %fc.2.running_var) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:983:0\n",
      "  %2199 : Float(1:1024, 1024:1, requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%2198, %fc.4.weight, %fc.4.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1690:0\n",
      "  %2200 : Float(1:1024, 1024:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2199) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1134:0\n",
      "  %2201 : Float(1:1024, 1024:1, requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%2200, %fc.6.weight, %fc.6.bias, %fc.6.running_mean, %fc.6.running_var) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:983:0\n",
      "  %2202 : Float(1:256, 256:1, requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%2201, %fc.8.weight, %fc.8.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1690:0\n",
      "  %2203 : Float(1:256, 256:1, requires_grad=1, device=cuda:0) = onnx::Relu(%2202) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1134:0\n",
      "  %2204 : Float(1:256, 256:1, requires_grad=1, device=cuda:0) = onnx::BatchNormalization[epsilon=1.0000000000000001e-05, momentum=0.90000000000000002](%2203, %fc.10.weight, %fc.10.bias, %fc.10.running_mean, %fc.10.running_var) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:983:0\n",
      "  %biqa_score : Float(1:1, 1:1, requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%2204, %fc.12.weight, %fc.12.bias) # /home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/torch/nn/functional.py:1690:0\n",
      "  return (%biqa_score)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "onnx_model_name = \"biqa.onnx\"\n",
    "input_names = [\"input_image\"]\n",
    "output_names = [\"biqa_score\"]\n",
    "dynamic_axes = {input_names[0] : {0: \"batch_size\"}, output_names[0] : {0: \"batch_size\"}}\n",
    "input_shape = [1, 3, 384, 512]\n",
    "dummy_input = torch.randn(*input_shape, device='cuda')\n",
    "torch.onnx.export(KonCept512, dummy_input, onnx_model_name, verbose=True, input_names=input_names, output_names=output_names, dynamic_axes=dynamic_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/tensorflow_addons/utils/ensure_tf_install.py:38: UserWarning: You are currently using a nightly version of TensorFlow (2.4.0-dev20201023). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "\n",
    "onnx_model = onnx.load(onnx_model_name)  # load onnx model\n",
    "tf_rep = prepare(onnx_model)  # prepare tf representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BIQA score of image `../pp2020_dev/11396447303.jpg` is 67.04446411132812\n",
      "The BIQA score of image `../pp2020_dev/107505789.jpg` is 58.35835266113281\n",
      "The BIQA score of image `../pp2020_dev/10692667386.jpg` is 65.37245178222656\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop, Normalization\n",
    "\n",
    "center_crop = CenterCrop(384, 512)\n",
    "normalization = Normalization(axis=1)\n",
    "normalization.build(input_shape)\n",
    "normalization._set_state_variables({\"mean\": [0.5, 0.5, 0.5], \"variance\": [0.5**2, 0.5**2, 0.5**2]})\n",
    "\n",
    "def preprocess(image_path):\n",
    "    image_raw = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image_raw)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.0\n",
    "    image = image[None, ...]\n",
    "    image = center_crop(image)\n",
    "    image = tf.transpose(image, perm=[0, 3, 1, 2])\n",
    "    image = normalization(image)\n",
    "    return image\n",
    "\n",
    "# tf_model = tf.saved_model.load(tf_model_name)\n",
    "tf_model = tf_rep.tf_module\n",
    "imgs = [preprocess(img_path) for img_path in img_paths]\n",
    "score = tf.squeeze(tf_model(input_image=tf.concat(imgs, axis=0))[0])\n",
    "for i, img_path in enumerate(img_paths):\n",
    "    print('The BIQA score of image `{}` is {}'.format(img_path, score[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
