{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import load_model, model_from_json, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.preprocessing import image as kpi\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_data(img_path, image_size, space='rgb'):\n",
    "    if space=='rgb':\n",
    "        img = kpi.load_img(img_path, target_size=image_size)\n",
    "        x = kpi.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        data = x[0]\n",
    "    elif space=='gray':\n",
    "        img = kpi.load_img(img_path, target_size=image_size, grayscale=True)\n",
    "        x = kpi.img_to_array(img)\n",
    "        x /= 255.\n",
    "        data = x\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG_FCN():\n",
    "    i_x = Input(shape=(480, 640, 3))\n",
    "    x = VGG16(include_top=False, weights='imagenet')(i_x)\n",
    "    x = Lambda(lambda x: x/255.)(x)\n",
    "    o_x = Conv2D(1, kernel_size=(3,3), strides=(1,1),padding=\"SAME\")(x)\n",
    "    model = Model(inputs=i_x, outputs=o_x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 480, 640, 3)]     0         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, None, None, 512)   14714688  \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 15, 20, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 15, 20, 1)         4609      \n",
      "=================================================================\n",
      "Total params: 14,719,297\n",
      "Trainable params: 14,719,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = VGG_FCN()\n",
    "model.summary()\n",
    "model.compile(loss='mse', optimizer=\"sgd\", metrics=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/698 [00:00<?, ?it/s]/home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n",
      "100%|██████████| 698/698 [00:11<00:00, 63.37it/s]\n"
     ]
    }
   ],
   "source": [
    "X = np.zeros((698, 480, 640, 3), np.float32)\n",
    "Y = np.zeros((698, 15, 20, 1), np.float32)\n",
    "\n",
    "for img_id in tqdm(range(698)):\n",
    "    x = get_image_data('./EMOd/images/%04d.jpg'%(img_id+1), (480, 640), 'rgb')\n",
    "    y = get_image_data('./EMOd/sensitivity/%04d_sensitivity.jpg'%(img_id+1), (15, 20), 'gray')\n",
    "    X[img_id] = x\n",
    "    Y[img_id] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "140/140 [==============================] - 473s 3s/step - loss: 0.1155 - val_loss: 0.0580\n",
      "Epoch 2/30\n",
      "140/140 [==============================] - 398s 3s/step - loss: 0.0788 - val_loss: 0.0746\n",
      "Epoch 3/30\n",
      "140/140 [==============================] - 401s 3s/step - loss: 0.0739 - val_loss: 0.0576\n",
      "Epoch 4/30\n",
      "140/140 [==============================] - 415s 3s/step - loss: 0.0686 - val_loss: 0.0637\n",
      "Epoch 5/30\n",
      "140/140 [==============================] - 428s 3s/step - loss: 0.0675 - val_loss: 0.0531\n",
      "Epoch 6/30\n",
      "140/140 [==============================] - 408s 3s/step - loss: 0.0626 - val_loss: 0.0599\n",
      "Epoch 7/30\n",
      "140/140 [==============================] - 423s 3s/step - loss: 0.0618 - val_loss: 0.0555\n",
      "Epoch 8/30\n",
      "140/140 [==============================] - 402s 3s/step - loss: 0.0640 - val_loss: 0.0540\n",
      "Epoch 9/30\n",
      "140/140 [==============================] - 411s 3s/step - loss: 0.0595 - val_loss: 0.0828\n",
      "Epoch 10/30\n",
      "140/140 [==============================] - 385s 3s/step - loss: 0.0540 - val_loss: 0.0521\n",
      "Epoch 11/30\n",
      "140/140 [==============================] - 378s 3s/step - loss: 0.0524 - val_loss: 0.0532\n",
      "Epoch 12/30\n",
      "140/140 [==============================] - 379s 3s/step - loss: 0.0486 - val_loss: 0.0565\n",
      "Epoch 13/30\n",
      "140/140 [==============================] - 382s 3s/step - loss: 0.0457 - val_loss: 0.0537\n",
      "Epoch 14/30\n",
      "140/140 [==============================] - 380s 3s/step - loss: 0.0462 - val_loss: 0.1096\n",
      "Epoch 15/30\n",
      "140/140 [==============================] - 376s 3s/step - loss: 0.0442 - val_loss: 0.0816\n",
      "Epoch 16/30\n",
      "140/140 [==============================] - 379s 3s/step - loss: 0.0442 - val_loss: 0.0534\n",
      "Epoch 17/30\n",
      "140/140 [==============================] - 381s 3s/step - loss: 0.0382 - val_loss: 0.0531\n",
      "Epoch 18/30\n",
      "140/140 [==============================] - 381s 3s/step - loss: 0.0381 - val_loss: 0.0526\n",
      "Epoch 19/30\n",
      "140/140 [==============================] - 380s 3s/step - loss: 0.0330 - val_loss: 0.0522\n",
      "Epoch 20/30\n",
      "140/140 [==============================] - 378s 3s/step - loss: 0.0341 - val_loss: 0.0535\n",
      "Epoch 21/30\n",
      "140/140 [==============================] - 381s 3s/step - loss: 0.0316 - val_loss: 0.0561\n",
      "Epoch 22/30\n",
      "140/140 [==============================] - 381s 3s/step - loss: 0.0318 - val_loss: 0.0612\n",
      "Epoch 23/30\n",
      "140/140 [==============================] - 384s 3s/step - loss: 0.0326 - val_loss: 0.0535\n",
      "Epoch 24/30\n",
      "140/140 [==============================] - 421s 3s/step - loss: 0.0279 - val_loss: 0.0565\n",
      "Epoch 25/30\n",
      "140/140 [==============================] - 420s 3s/step - loss: 0.0269 - val_loss: 0.0609\n",
      "Epoch 26/30\n",
      "140/140 [==============================] - 419s 3s/step - loss: 0.0255 - val_loss: 0.0536\n",
      "Epoch 27/30\n",
      "140/140 [==============================] - 424s 3s/step - loss: 0.0240 - val_loss: 0.0566\n",
      "Epoch 28/30\n",
      "140/140 [==============================] - 420s 3s/step - loss: 0.0249 - val_loss: 0.0544\n",
      "Epoch 29/30\n",
      "140/140 [==============================] - 427s 3s/step - loss: 0.0233 - val_loss: 0.0551\n",
      "Epoch 30/30\n",
      "140/140 [==============================] - 389s 3s/step - loss: 0.0216 - val_loss: 0.0592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc730295df0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=4, shuffle=True, epochs=30, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc7a3d90b50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.expand_dims(get_image_data('./EMOd/images/0003.jpg', (480, 640), 'rgb'), axis=0)\n",
    "y = model.predict(x)\n",
    "plt.imshow(y[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "/home/mathsci/miniconda3/envs/n-cript/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:1397: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`layer.updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: sensitivity_map_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('sensitivity_map_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc7a322ba60>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = load_model('sensitivity_map_model')\n",
    "new_y = model.predict(x)\n",
    "plt.imshow(new_y[0,:,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
